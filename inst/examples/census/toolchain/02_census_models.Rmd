---
title: "Census Data Predictive Models"
output: html_notebook
---

# Overview

In the previous step we explored the data and created plots using the `tidyverse` and `htmlwidgets`. In this step we will create two statistical models that predict income over `$50k`. The first model is a classic logistic model and the second model uses the elastic net with regularization L1 and L2 penalties. All predictors will be categorical in this analysis.

```{r setup, warning=FALSE, message=FALSE}
library(tidyverse)
library(plotly)
library(pROC)
library(glmnet)

train <- read_csv("data/train.csv")
test <- read_csv("data/test.csv")
```

# Logistic Regression

The logistic model uses main effects only against the training data. No regularization is applied. We assess the model fit with a hold out sample. We can build logistic models with the `stats` package.

## Train Model

Gender, education, and marital status are all highly significant. Marrital status in particular is a good predictor of those earning more than $50k.

```{r}
m1 <- glm(label ~ gender + native_country + education + occupation + workclass + marital_status +  
         race + age_buckets, binomial, train)
summary(m1)
#anova(m1) # takes a while to run
#plot(m1) # legacy plots not that useful
```

## Predict

The high area under the curve (AUC) of 0.883 indicator that this model might be overfitting. The lift chart shows that 80% of those in the uppper decile earn more than `$50k`, compared to a tiny fraction in the lower decile.

```{r}
# Predict
pred <- bind_rows("train" = train, "test" = test, .id = "data") %>%
  mutate(pred = predict(m1, ., type = "response")) %>%
  mutate(decile = ntile(desc(pred), 10)) %>%
  select(data, label, pred, decile)

# ROC plot
pred %>%
  filter(data == "test") %>%
  roc(label ~ pred, .) %>%
  plot.roc(., print.auc = TRUE) # maybe add accuracy like the TF example

# Lift plot
p <- pred %>%
  group_by(data, decile) %>%
  summarize(percent = 100 * mean(label)) %>%
  ggplot(aes(decile, percent, fill = data)) + geom_bar(stat = "Identity", position = "dodge") +
  ggtitle("Lift chart for logistic regression model")
ggplotly(p)
```


***

# Elastic net

The elastic net is a regularized regression method that uses L1 (lasso) and L2 (ridge) penalties. We can build elastic net models with the `glmnet` package.

## Train model

Whereas the logistic method used formulas, the elastic net model requires us to construct a model matrix from the categorical predictors. We then attempt to choose a value `lambda` that optimizes the L1 and L2 penalties. We can examine various predictor sets for different values of `lambda`. Optionally, we can use cross validation to programmatically determine the best choice of `lambda`.

```{r}
# Convert to factors
alldata <- bind_rows("train" = train, "test" = test, .id = "data") %>%
  select(-education_num) %>%
  mutate_each(., funs(factor(.))) %>%
  model.matrix( ~ ., .)

# Create training prediction matrix
train.factors <- list(x = alldata[alldata[,'datatrain'] == 1, -(1:3)],
                     y = alldata[alldata[,'datatrain'] == 1, 3])

# Create test prediction matrix
test.factors <- list(x = alldata[alldata[,'datatrain'] == 0, -(1:3)],
                    y = alldata[alldata[,'datatrain'] == 0, 3])

# Fit a regularized model
fit1 <- glmnet(train.factors$x, train.factors$y, "binomial")
plot(fit1)
print(fit1)
coef.glmnet(fit1, s = 0.03) # extract coefficients at a single value of lambda
```

```{r, eval=FALSE}
# Cross validation (long running for full dataset)
cvfit <- cv.glmnet(train.factors$x, train.factors$y, family = "binomial", type.measure = "class")
plot(cvfit)
cvfit$lambda.min # 0.0001971255
```

## Predict

Once you have chosen a value for `lambda` you can score the test set and examine the ROC and lift charts. This model has a slightly smaller AUC and lift values, but the overall results look very similar to logistic regression.

```{r}
# Predict and plot the AUC
test.factors$pred <- predict.glmnet(fit1, test.factors$x, s=0.02) # make predictions
data.frame(resp = test.factors$y, pred = c(test.factors$pred)) %>%
  roc(resp ~ pred, .) %>%
  plot.roc(., print.auc = TRUE)

# Lift chart
p <- data.frame(data = ifelse(alldata[, 'datatrain'], "train", "test"),
           label = alldata[,'label1'],
           pred = c(predict.glmnet(fit1, alldata[, -(1:3)], s=0.02))) %>%
  mutate(decile = ntile(desc(pred), 10)) %>%
  group_by(data, decile) %>%
  summarize(percent = 100 * mean(label)) %>%
  ggplot(aes(decile, percent, fill = data)) + geom_bar(stat = "Identity", position = "dodge") +
  ggtitle("Lift chart for elastic net model")
ggplotly(p)
```

# Save

Finally, save the predicted output and the model for building apps.

```{r}
# Score predictions
pred.out <- test %>%
  mutate(pred = predict(m1, ., type = "response")) %>%
  mutate(decile = ntile(desc(pred), 10)) %>%
  mutate(income_bracket = ifelse(label, ">50K", "<=50K")
)

# Output predictions to file
write_csv(pred.out, "data/pred.csv")
save(m1, file = "data/logisticModel.Rdata")
saveRDS(m1, file = "data/logisticModel.rds")
```

